# rl-taxi
HUST, CS, 2022 Reinforcement Learning, Course project  
基于强化学习的出租车调度问题

## 游戏模型 Taxi-vx
基于 `gym` 中 Taxi-v3 小游戏拓展的 **Taxi-vx 游戏模型**, 可自定义出租车中的地图、地点位置及数量、乘客数量.
### 游戏规则
1. $m\times n$ 的地图, 地图上有 $s$ 个地点, $t$ 名乘客.
2. 乘客随机在 $s$ 个地点中出现, 并将其他地点中的一个作为目的地. 同一乘客的位置和其目的地为不同地点, 不同**乘客可在相同位置可有相同目的地**.
3. 其中地图中有 `:` 和 `|` 两种类型的栅栏, 前者出租车可以穿越, 后者则不能.  
4. 游戏任务: 控制一辆在任意地点生成的出租车, 将所有乘客接送至其目的地, 越快越好. 出租车可以**同时接送多名乘客**.
5. 出租车在地图上的**任一位置**都有 6 个动作可以选择, 分别是: 向上、向下、向左、向右、接上乘客和放下乘客.
### 奖励机制
Taxi-vx 游戏模型中, 奖励机制包括**移动奖励**和**操作奖励**两类.
1. 移动奖励主要是根据出租车在地图中移动所产生的奖励, 包括:
    1. 每移动一步扣 2 分
    2. 碰到栅栏 `|` 时扣 10 分 (+)
    3. 距离乘客或目的地更近则额外加 1 分 (+)
    4. 走回头路扣 5 分 (+)
2. 操作奖励主要是出租车的接上乘客和放下乘客两个操作所产生的奖励, 包括: 
    1. 将乘客成功送至目的地加 20 分
    2. 错误地接上乘客和放下乘客扣 10 分
    3. 将乘客成功接上车加 5 分 (+)
* 注: 带 "(+)" 的奖励机制为 `gym` 中 Taxi-v3 中所不具有的奖励机制

* 标准化奖励值公式: 
$$
normalized\_rewards=(move\_rewards\times\sqrt\frac{5\times5}{m\times n}+opt\_rewards)\div t
$$

## 项目组成
### 基本
* `requirement.txt`: python 环境依赖包列表
### 游戏模型
* `env.py`: . 包括: 游戏模型的具体实现代码, 及地图切片代码
* `config.py`: 有关地图, 乘客位置及数量的配置
* `game.py`: 可以人工操作的游戏, 在控制台运行. 方向键 ↑ ↓ ← → 控制出租车移动, s 键接上乘客, x 键放下乘客.
### 强化学习模型
* `agents`: 智能体实现目录. 包括:
  * `agent.py`: 智能体抽象基类
  * `ddqn.py`: 基于 DDQN(Double Deep Q-Learning) 算法的深度强化学习的智能体
  * `sarsa.py`, `q_learning.py` 等: 5 种传统强化学习方法的智能体
* `policy.py`: 策略类, 此项目中只实现了贪婪策略和 $\epsilon$-贪婪策略
* `main.py`: 使用以上强化学习方法模型进行 Taxi-vx 游戏的训练入口文件. 可根据需要自行添加代码.

## 分支说明
* `master`: 主分支. 实现了以上**所有奖励机制**并**没有出租车接放乘客限制**的最终版本.
* `original`: 仅额外实现了**奖励机制 2-3** 的最初版本.
* `loc_pick_drop`: 在 `original` 分支的基础上增加了"**仅地图中的地点**(即乘客的位置或其目的地)出租车**才可接放乘客**"的限制.
* `loc_pd_reward_opt`: 在 `loc_pick_drop` 分支的基础上**增加了奖励机制 1-2 和 1-3**.
* `only_reward_opt`: 在 `loc_pd_reward_opt` 分支的基础上**移除了出租车接放乘客的限制**.